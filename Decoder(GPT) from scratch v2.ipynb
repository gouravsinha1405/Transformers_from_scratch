{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN2/FirojeAbNPp6+A+cmIe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"IiRjK6PSWuSc","executionInfo":{"status":"ok","timestamp":1682970938811,"user_tz":-330,"elapsed":5752,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from tqdm import tqdm\n","import math"]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"agbMFptlXG1r","executionInfo":{"status":"ok","timestamp":1682971009215,"user_tz":-330,"elapsed":7,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"fcedc8d4-24fa-4544-fe8b-57cd16f023e4"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cpu'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["dropout_prob = 0.2\n","class Embedding(nn.Module):\n","\n","  def __init__(self, vocab_size, embed_size):\n","    super().__init__()\n","    self.token_embeddings = nn.Embedding(vocab_size, embed_size)\n","  \n","  def forward(self, input):\n","    out = self.token_embeddings(input)\n","    # print(out.shape)\n","    return out\n","\n","class PositionalEmbedding(nn.Module):\n","  \"\"\"For every token in context length we will generate a positional encoding\"\"\"\n","\n","  def __init__(self, context_len, embed_size):\n","    super().__init__()\n","    pos_encoding = torch.zeros(context_len, embed_size)\n","    for pos in range(context_len):\n","      for i in range(0,embed_size,2):\n","        pos_encoding[pos,i] = math.sin(pos / (10000 ** ((2 * i)/embed_size)))\n","        pos_encoding[pos, i+1] = math.cos(pos / (10000 ** ((2 * (i + 1))/embed_size)))\n","    pos_encoding = pos_encoding.unsqueeze(dim=0)\n","    pos_encoding = pos_encoding\n","    # self.dropout = nn.Dropout(dropout_prob)\n","    self.register_buffer('pe',pos_encoding)\n","  \n","  def forward(self, input):\n","    context_len = input.shape[1]\n","    # print(context_len)\n","    # print(input.shape)\n","    # print(self.pe[:,:context_len].shape)\n","    input = input + self.pe[:,:context_len,:]\n","    # input = input + torch.autograd.Variable(self.pe[:,:context_len],requires_grad=False)\n","    return input\n","#------self attention with single head----------#\n","class Head(nn.Module):\n","\n","  def __init__(self,head_size,embed_size,context_length):\n","    super().__init__()\n","\n","    self.query = nn.Linear(embed_size, head_size, bias=False)\n","    self.key = nn.Linear(embed_size, head_size, bias=False)\n","    self.value = nn.Linear(embed_size, head_size, bias=False)\n","    self.dropout = nn.Dropout(dropout_prob)\n","    self.register_buffer('tril',torch.tril(torch.ones(context_length, context_length)))\n","  \n","  def forward(self, q, k, v, pad_mask=None):\n","    batch_size, context_len, embed_size = q.shape\n","    q = self.query(q)\n","    k = self.key(k)\n","    v = self.value(v)\n","    # print(q.shape, k.shape, v.shape)\n","    weights = q @ k.transpose(-2,-1) * embed_size**-0.5\n","    if pad_mask is not None:\n","      weigths = weights.masked_fill(pad_mask[:,None, None, :] == 0, float('-inf'))\n","    #--this is the causal mask--#\n","    weights = weights.masked_fill(self.tril[:context_len,:context_len]==0, float('-inf'))\n","    # print(weights[0])\n","    weights = F.softmax(weights, dim=-1)\n","    weights = self.dropout(weights)\n","    out = weights @ v\n","    return out\n","#-----multihead attention------#\n","class MultiHeadAttention(nn.Module):\n","\n","  def __init__(self, num_heads, head_size,embed_size,context_length):\n","    super().__init__()\n","    self.multiheads = nn.ModuleList([Head(head_size,embed_size,context_length) for _ in range(num_heads)])\n","    self.projection = nn.Linear(embed_size, embed_size)\n","    self.dropout = nn.Dropout(dropout_prob)\n","  \n","  def forward(self,q,k,v,pad_mask=None):\n","    out = torch.cat([h(q,k,v,pad_mask) for h in self.multiheads], dim = -1)\n","    return self.dropout(self.projection(out))\n","#---------Feedforward--------------#\n","class FeedForward(nn.Module):\n","  \"\"\"Self attention while calculates the interactions among the tokens the feedforward will train the model on\n","  individual tokens and try to extract the information individually\"\"\"\n","  def __init__(self,embed_size):\n","    super().__init__()\n","    self.neural_net = nn.Sequential(\n","        nn.Linear(embed_size, 4 * embed_size), # multiplying by 4 as per the paper 'attention is all you need', this expands the hidden layer\n","        nn.GELU(),\n","        nn.Linear(4 * embed_size, embed_size), #--projection layer \n","        nn.Dropout(dropout_prob)\n","    )\n","  def forward(self, x):\n","    return self.neural_net(x)\n","\n","\n"],"metadata":{"id":"6mDyWIdtXNqC","executionInfo":{"status":"ok","timestamp":1682970965109,"user_tz":-330,"elapsed":2,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class DecoderBlock(nn.Module):\n","\n","  def __init__(self, num_heads, embed_size,context_length):\n","    super().__init__()\n","    head_size = embed_size // num_heads\n","    self.masked_multiheads = MultiHeadAttention(num_heads, head_size,embed_size,context_length)\n","    self.multiheads = MultiHeadAttention(num_heads, head_size,embed_size,context_length)\n","    self.feedforward = FeedForward(embed_size)\n","    self.ln1 = nn.LayerNorm(embed_size)\n","    self.ln2 = nn.LayerNorm(embed_size)\n","    self.ln3 = nn.LayerNorm(embed_size)\n","    self.dropout1 = nn.Dropout(dropout_prob)\n","    self.dropout2 = nn.Dropout(dropout_prob)\n","    self.dropout3 = nn.Dropout(dropout_prob)\n","\n","  def forward(self,input,pad_mask=None):\n","    #adding residual connection\n","    input = input + self.dropout1(self.masked_multiheads(self.ln1(input),self.ln1(input),self.ln1(input), pad_mask = pad_mask))\n","    # targets += self.dropout1(self.masked_multiheads(self.ln1(targets),self.ln1(targets),self.ln1(targets), mask = True))\n","    # if out_from_encoder is not None:\n","    #   targets += self.dropout2(self.multiheads(self.ln2(targets),self.ln2(out_from_encoder),self.ln2(out_from_encoder),mask=True))\n","    out  = input + self.dropout3(self.feedforward(self.ln3(input)))\n","    return out\n","\n","class Decoder(nn.Module):\n","\n","  def __init__(self, num_blocks, context_length, embed_size, num_heads, head_size, vocab_size):\n","    super().__init__()\n","    self.embeddings = Embedding(vocab_size,embed_size)\n","    self.position_embeddings = PositionalEmbedding(context_length, embed_size)\n","    self.decoder_blocks = nn.Sequential(*[DecoderBlock(num_heads, embed_size,context_length) for _ in range(num_blocks)])\n","    self.ln1 = nn.LayerNorm(embed_size)\n","    self.linear_layer = nn.Linear(embed_size, vocab_size)\n","  \n","  def forward(self, input, pad_mask = None):\n","    embed_output = self.embeddings(input)\n","    pos_out = self.position_embeddings(embed_output) #----these are our inputs to the block\n","    for block in self.decoder_blocks:\n","      pos_out = block(pos_out, pad_mask)\n","    out = self.ln1(pos_out)\n","    out = self.linear_layer(out)\n","    # out_probs = F.softmax(self.linear_layer(pos_out), dim = -1)\n","    return out\n","\n","    \n","\n","\n"],"metadata":{"id":"MCsEoLpTXdqi","executionInfo":{"status":"ok","timestamp":1682970970664,"user_tz":-330,"elapsed":2,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Testing the decoder"],"metadata":{"id":"iLn4GLSAhquS"}},{"cell_type":"code","source":["num_blocks, context_length, embed_size, num_heads, head_size, vocab_size, batch_size,num_clases = 2, 1024, 64, 4, 16, 20000, 64,5"],"metadata":{"id":"GxFmBvYxhqbK","executionInfo":{"status":"ok","timestamp":1682970977590,"user_tz":-330,"elapsed":2,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["model = Decoder(num_blocks, context_length, embed_size, num_heads, head_size, vocab_size)"],"metadata":{"id":"G7G_9SI5hxLy","executionInfo":{"status":"ok","timestamp":1682970980893,"user_tz":-330,"elapsed":2677,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dsxcsI50h7Yi","executionInfo":{"status":"ok","timestamp":1682971015170,"user_tz":-330,"elapsed":3,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"e355cdd5-0b4e-40ee-8470-bfd95bd9c38f"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Decoder(\n","  (embeddings): Embedding(\n","    (token_embeddings): Embedding(20000, 64)\n","  )\n","  (position_embeddings): PositionalEmbedding()\n","  (decoder_blocks): Sequential(\n","    (0): DecoderBlock(\n","      (masked_multiheads): MultiHeadAttention(\n","        (multiheads): ModuleList(\n","          (0-3): 4 x Head(\n","            (query): Linear(in_features=64, out_features=16, bias=False)\n","            (key): Linear(in_features=64, out_features=16, bias=False)\n","            (value): Linear(in_features=64, out_features=16, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (projection): Linear(in_features=64, out_features=64, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (multiheads): MultiHeadAttention(\n","        (multiheads): ModuleList(\n","          (0-3): 4 x Head(\n","            (query): Linear(in_features=64, out_features=16, bias=False)\n","            (key): Linear(in_features=64, out_features=16, bias=False)\n","            (value): Linear(in_features=64, out_features=16, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (projection): Linear(in_features=64, out_features=64, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (feedforward): FeedForward(\n","        (neural_net): Sequential(\n","          (0): Linear(in_features=64, out_features=256, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Linear(in_features=256, out_features=64, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","      (ln3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","      (dropout1): Dropout(p=0.2, inplace=False)\n","      (dropout2): Dropout(p=0.2, inplace=False)\n","      (dropout3): Dropout(p=0.2, inplace=False)\n","    )\n","    (1): DecoderBlock(\n","      (masked_multiheads): MultiHeadAttention(\n","        (multiheads): ModuleList(\n","          (0-3): 4 x Head(\n","            (query): Linear(in_features=64, out_features=16, bias=False)\n","            (key): Linear(in_features=64, out_features=16, bias=False)\n","            (value): Linear(in_features=64, out_features=16, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (projection): Linear(in_features=64, out_features=64, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (multiheads): MultiHeadAttention(\n","        (multiheads): ModuleList(\n","          (0-3): 4 x Head(\n","            (query): Linear(in_features=64, out_features=16, bias=False)\n","            (key): Linear(in_features=64, out_features=16, bias=False)\n","            (value): Linear(in_features=64, out_features=16, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (projection): Linear(in_features=64, out_features=64, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (feedforward): FeedForward(\n","        (neural_net): Sequential(\n","          (0): Linear(in_features=64, out_features=256, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Linear(in_features=256, out_features=64, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","      (ln3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","      (dropout1): Dropout(p=0.2, inplace=False)\n","      (dropout2): Dropout(p=0.2, inplace=False)\n","      (dropout3): Dropout(p=0.2, inplace=False)\n","    )\n","  )\n","  (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","  (linear_layer): Linear(in_features=64, out_features=20000, bias=True)\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["x = torch.randint(0,20000,(8,512))\n","x = x.to(device)"],"metadata":{"id":"UH39ImJeh4KY","executionInfo":{"status":"ok","timestamp":1682971020783,"user_tz":-330,"elapsed":1448,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["mask = torch.ones((8,512))\n","mask[:,256:] = 0\n","mask = mask.to(device)"],"metadata":{"id":"OhWu4HILigkp","executionInfo":{"status":"ok","timestamp":1682971020784,"user_tz":-330,"elapsed":3,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["y = model(x, mask)"],"metadata":{"id":"5UcvWS9UinIx","executionInfo":{"status":"ok","timestamp":1682971024744,"user_tz":-330,"elapsed":1529,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d1o2VhX-jZFy","executionInfo":{"status":"ok","timestamp":1682971024744,"user_tz":-330,"elapsed":4,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"523a05e3-da84-426f-b860-a10088e2d5ea"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([8, 512, 20000])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["!pip install transformers datasets"],"metadata":{"id":"XLesN79BjaBb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer, DataCollatorWithPadding\n","checkpoint = 'distilbert-base-cased'\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","from datasets import load_dataset\n","raw_dataset = load_dataset(\"glue\",\"sst2\")"],"metadata":{"id":"DlbKD2IukA30"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenize_fn(batch):\n","  return tokenizer(batch['sentence'], truncation=True)\n","tokenized_datasets = raw_dataset.map(tokenize_fn,batched=True)\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"],"metadata":{"id":"TiPfxWTDkT77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_collator"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I76L83aok0Jt","executionInfo":{"status":"ok","timestamp":1682747893580,"user_tz":-330,"elapsed":3,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"9af79328-635c-4a60-f63b-f34aa9c536c7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataCollatorWithPadding(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["raw_dataset"],"metadata":{"id":"SjnPTEyllA_D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682747900325,"user_tz":-330,"elapsed":681,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"8a981e59-ef38-4222-d85d-3331bf011d08"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['sentence', 'label', 'idx'],\n","        num_rows: 67349\n","    })\n","    validation: Dataset({\n","        features: ['sentence', 'label', 'idx'],\n","        num_rows: 872\n","    })\n","    test: Dataset({\n","        features: ['sentence', 'label', 'idx'],\n","        num_rows: 1821\n","    })\n","})"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["tokenized_datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uazAslAflESJ","executionInfo":{"status":"ok","timestamp":1682747906708,"user_tz":-330,"elapsed":1313,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"22e840dc-57f6-42a6-8b04-87eaac2d01d2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n","        num_rows: 67349\n","    })\n","    validation: Dataset({\n","        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n","        num_rows: 872\n","    })\n","    test: Dataset({\n","        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n","        num_rows: 1821\n","    })\n","})"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["tokenized_datasets = tokenized_datasets.remove_columns([\"sentence\",\"idx\",\"label\"])"],"metadata":{"id":"LVkdrwuFlZTL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","train_loader = DataLoader(tokenized_datasets['train'],\n","                          shuffle = True,\n","                          batch_size = 32,\n","                          collate_fn = data_collator)"],"metadata":{"id":"KQBzdSxPlcqD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for batch in train_loader:\n","  for k, v in batch.items():\n","    print(k,v.shape)\n","  break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gIosiT8emPTg","executionInfo":{"status":"ok","timestamp":1682747968613,"user_tz":-330,"elapsed":4,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"9c8083f5-3d70-4701-f463-0a04eb1ea73f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"stream","name":"stdout","text":["input_ids torch.Size([32, 55])\n","attention_mask torch.Size([32, 55])\n"]}]},{"cell_type":"code","source":["tokenizer.pad_token_id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ycsZhg6nBtU","executionInfo":{"status":"ok","timestamp":1682747969307,"user_tz":-330,"elapsed":2,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"6c353896-4d1a-405e-ea5c-ed5d3f131b43"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["model = Decoder(num_blocks = 4, \n","                embed_size = 512, \n","                num_heads = 8, \n","                head_size=16, \n","                vocab_size=tokenizer.vocab_size,\n","                context_length=tokenizer.max_model_input_sizes[checkpoint])\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"znD9QI_TnE4Z","executionInfo":{"status":"ok","timestamp":1682747979954,"user_tz":-330,"elapsed":4762,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"3f1078a9-a140-4a9f-f7c0-7a4eb1ef8a99"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Decoder(\n","  (embeddings): Embedding(\n","    (token_embeddings): Embedding(28996, 512)\n","  )\n","  (position_embeddings): PositionalEmbedding()\n","  (decoder_blocks): Sequential(\n","    (0): DecoderBlock(\n","      (masked_multiheads): MultiHeadAttention(\n","        (multiheads): ModuleList(\n","          (0-7): 8 x Head(\n","            (query): Linear(in_features=512, out_features=64, bias=False)\n","            (key): Linear(in_features=512, out_features=64, bias=False)\n","            (value): Linear(in_features=512, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (projection): Linear(in_features=512, out_features=512, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (multiheads): MultiHeadAttention(\n","        (multiheads): ModuleList(\n","          (0-7): 8 x Head(\n","            (query): Linear(in_features=512, out_features=64, bias=False)\n","            (key): Linear(in_features=512, out_features=64, bias=False)\n","            (value): Linear(in_features=512, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (projection): Linear(in_features=512, out_features=512, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (feedforward): FeedForward(\n","        (neural_net): Sequential(\n","          (0): Linear(in_features=512, out_features=2048, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Linear(in_features=2048, out_features=512, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (ln3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (dropout1): Dropout(p=0.2, inplace=False)\n","      (dropout2): Dropout(p=0.2, inplace=False)\n","      (dropout3): Dropout(p=0.2, inplace=False)\n","    )\n","    (1): DecoderBlock(\n","      (masked_multiheads): MultiHeadAttention(\n","        (multiheads): ModuleList(\n","          (0-7): 8 x Head(\n","            (query): Linear(in_features=512, out_features=64, bias=False)\n","            (key): Linear(in_features=512, out_features=64, bias=False)\n","            (value): Linear(in_features=512, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (projection): Linear(in_features=512, out_features=512, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (multiheads): MultiHeadAttention(\n","        (multiheads): ModuleList(\n","          (0-7): 8 x Head(\n","            (query): Linear(in_features=512, out_features=64, bias=False)\n","            (key): Linear(in_features=512, out_features=64, bias=False)\n","            (value): Linear(in_features=512, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (projection): Linear(in_features=512, out_features=512, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (feedforward): FeedForward(\n","        (neural_net): Sequential(\n","          (0): Linear(in_features=512, out_features=2048, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Linear(in_features=2048, out_features=512, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (ln3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (dropout1): Dropout(p=0.2, inplace=False)\n","      (dropout2): Dropout(p=0.2, inplace=False)\n","      (dropout3): Dropout(p=0.2, inplace=False)\n","    )\n","    (2): DecoderBlock(\n","      (masked_multiheads): MultiHeadAttention(\n","        (multiheads): ModuleList(\n","          (0-7): 8 x Head(\n","            (query): Linear(in_features=512, out_features=64, bias=False)\n","            (key): Linear(in_features=512, out_features=64, bias=False)\n","            (value): Linear(in_features=512, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (projection): Linear(in_features=512, out_features=512, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (multiheads): MultiHeadAttention(\n","        (multiheads): ModuleList(\n","          (0-7): 8 x Head(\n","            (query): Linear(in_features=512, out_features=64, bias=False)\n","            (key): Linear(in_features=512, out_features=64, bias=False)\n","            (value): Linear(in_features=512, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (projection): Linear(in_features=512, out_features=512, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (feedforward): FeedForward(\n","        (neural_net): Sequential(\n","          (0): Linear(in_features=512, out_features=2048, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Linear(in_features=2048, out_features=512, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (ln3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (dropout1): Dropout(p=0.2, inplace=False)\n","      (dropout2): Dropout(p=0.2, inplace=False)\n","      (dropout3): Dropout(p=0.2, inplace=False)\n","    )\n","    (3): DecoderBlock(\n","      (masked_multiheads): MultiHeadAttention(\n","        (multiheads): ModuleList(\n","          (0-7): 8 x Head(\n","            (query): Linear(in_features=512, out_features=64, bias=False)\n","            (key): Linear(in_features=512, out_features=64, bias=False)\n","            (value): Linear(in_features=512, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (projection): Linear(in_features=512, out_features=512, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (multiheads): MultiHeadAttention(\n","        (multiheads): ModuleList(\n","          (0-7): 8 x Head(\n","            (query): Linear(in_features=512, out_features=64, bias=False)\n","            (key): Linear(in_features=512, out_features=64, bias=False)\n","            (value): Linear(in_features=512, out_features=64, bias=False)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (projection): Linear(in_features=512, out_features=512, bias=True)\n","        (dropout): Dropout(p=0.2, inplace=False)\n","      )\n","      (feedforward): FeedForward(\n","        (neural_net): Sequential(\n","          (0): Linear(in_features=512, out_features=2048, bias=True)\n","          (1): GELU(approximate='none')\n","          (2): Linear(in_features=2048, out_features=512, bias=True)\n","          (3): Dropout(p=0.2, inplace=False)\n","        )\n","      )\n","      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (ln3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      (dropout1): Dropout(p=0.2, inplace=False)\n","      (dropout2): Dropout(p=0.2, inplace=False)\n","      (dropout3): Dropout(p=0.2, inplace=False)\n","    )\n","  )\n","  (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","  (linear_layer): Linear(in_features=512, out_features=28996, bias=True)\n",")"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n","optimizer = torch.optim.AdamW(model.parameters())"],"metadata":{"id":"JXf3og2anRW8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datetime import datetime\n","import numpy as np\n","# model training\n","\n","def train(model, criterion, optimizer, train_loader, epochs):\n","  train_losses = np.zeros(epochs)\n","  # test_losses = np.zeros(epochs)\n","\n","  for i in range(epochs):\n","    model.train()\n","    t0 = datetime.now()\n","    train_loss = []\n","    n_train = 0\n","    for batch in train_loader:\n","      batch = {k: v.to(device) for k , v in batch.items()}\n","      optimizer.zero_grad()\n","      targets = batch['input_ids'].clone().detach()\n","      targets = torch.roll(targets, shifts=-1, dims=1)\n","      targets[:,-1] = tokenizer.pad_token_id\n","      outputs = model(batch['input_ids'], batch['attention_mask'])\n","      loss = criterion(outputs.transpose(2,1), targets)\n","      loss.backward()\n","      optimizer.step()\n","      train_loss.append(loss.item())\n","    train_loss = np.mean(train_loss) #average loss\n","\n","    # model.eval()\n","    # test_loss = 0\n","    # n_test = 0\n","    # for batch in valid_loader:\n","    #    batch = {k: v.to(device) for k , v in batch.items()}\n","    #    outputs = model(batch['input_ids'], batch['attention_mask'])\n","    #    loss = criterion(outputs, batch['labels'])\n","    #    test_loss += loss.item()*batch['input_ids'].size(0)\n","    #    n_test += batch['input_ids'].size(0)\n","    # test_loss = test_loss/n_test #average loss\n","    train_losses[i] = train_loss\n","    # test_losses[i] = test_loss\n","\n","    duration = datetime.now() - t0\n","    print(f\"Epoch {i+1}/{epochs}, \\\n","    Train Loss : {train_loss:.4f}, \\\n","    Duration: {duration}\")\n","  return train_losses"],"metadata":{"id":"CZxClBrWpCTm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_losses = train(\n","    model,\n","    criterion,\n","    optimizer,\n","    train_loader,\n","    epochs=15\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A-cTCNyzsX-L","executionInfo":{"status":"ok","timestamp":1682749855061,"user_tz":-330,"elapsed":1527795,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"616aaf98-3d57-4f97-fe2c-5fd61d9978af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15,     Train Loss : 4.7669,     Duration: 0:01:41.757727\n","Epoch 2/15,     Train Loss : 3.2761,     Duration: 0:01:41.396047\n","Epoch 3/15,     Train Loss : 2.5829,     Duration: 0:01:41.460361\n","Epoch 4/15,     Train Loss : 2.2159,     Duration: 0:01:42.170310\n","Epoch 5/15,     Train Loss : 2.0006,     Duration: 0:01:41.544539\n","Epoch 6/15,     Train Loss : 1.8538,     Duration: 0:01:41.895752\n","Epoch 7/15,     Train Loss : 1.7507,     Duration: 0:01:41.546609\n","Epoch 8/15,     Train Loss : 1.6694,     Duration: 0:01:41.817958\n","Epoch 9/15,     Train Loss : 1.6087,     Duration: 0:01:41.712565\n","Epoch 10/15,     Train Loss : 1.5590,     Duration: 0:01:41.943966\n","Epoch 11/15,     Train Loss : 1.5179,     Duration: 0:01:42.014242\n","Epoch 12/15,     Train Loss : 1.4837,     Duration: 0:01:41.843878\n","Epoch 13/15,     Train Loss : 1.4519,     Duration: 0:01:41.737299\n","Epoch 14/15,     Train Loss : 1.4285,     Duration: 0:01:41.832658\n","Epoch 15/15,     Train Loss : 1.4051,     Duration: 0:01:41.962416\n"]}]},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"],"metadata":{"id":"ClHI_fxItbUs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('input.txt', 'r', encoding='utf-8') as f:\n","    text = f.read()"],"metadata":{"id":"wlJ2awPot30c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chars = sorted(list(set(text)))\n","stoi = {ch:i for i, ch in enumerate(chars)}\n","itos = {i:ch for i, ch in enumerate(chars)}\n","def encode(text):\n","  return [stoi[ch] for ch in text]\n","def decode(nums):\n","  return ''.join([itos[i] for i in nums])\n","vocab_size = len(chars)\n","data = torch.tensor(encode(text), dtype= torch.long)\n","n = int(0.9*len(data))\n","train_data = data[:n]\n","val_data = data[n:]\n","def get_batch(split):\n","  data = train_data if split == 'train' else val_data\n","  # generates 4 random starting indexes from 0 to len(data)-block_size\n","  ix = torch.randint(len(data)-context_length, (batch_size,))\n","  # stack all the data of contextual block size 8 on top of one another\n","  x = torch.stack([data[i:i+context_length] for i in ix])\n","  y = torch.stack([data[i+1:i+context_length+1] for i in ix])\n","  x, y = x.to(device), y.to(device)\n","  return x,y "],"metadata":{"id":"i-zPPSXct8TT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["valid_loader = DataLoader(tokenized_datasets['validation'],\n","                          batch_size = 32,\n","                          collate_fn = data_collator)"],"metadata":{"id":"Yg5PVzkO3IV9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","for batch in valid_loader:\n","  batch = {k: v.to(device) for k, v in batch.items()}\n","  outputs = model(batch['input_ids'], batch['attention_mask'])\n","  break\n","\n","\n","    \n","\n"],"metadata":{"id":"RT17DMTLvQnU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bcvDjY2o3BnD","executionInfo":{"status":"ok","timestamp":1682752493981,"user_tz":-330,"elapsed":3,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"bb874769-2d40-4615-df7a-39138cfe170b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 51, 28996])"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["torch.argmax(outputs, axis=-1).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cenr0LzU3U5i","executionInfo":{"status":"ok","timestamp":1682752856615,"user_tz":-330,"elapsed":2,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"6df53465-4827-472a-ff00-b16c0317beff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 51])"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["prdiction_ids = torch.argmax(outputs, axis=-1)"],"metadata":{"id":"Ky9ZRd-p3dFW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.decode(prdiction_ids[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"lld-GrR03rJ7","executionInfo":{"status":"ok","timestamp":1682752602444,"user_tz":-330,"elapsed":4,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"422aaadf-a7c0-41be-a87c-104d34285095"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"a's a pretty, funny funny story. [SEP] with of of a a a a a a a a a a a a a a a a a a a a a a apparent apparent apparent apparent a a a........\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["tokenizer.decode(batch['input_ids'][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"bZQxPTu53vRQ","executionInfo":{"status":"ok","timestamp":1682752988949,"user_tz":-330,"elapsed":1398,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"8506552c-53a7-44fe-b62a-180515373dc7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"[CLS] it's a charming and often affecting journey. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","source":["# generator"],"metadata":{"id":"kSwAOLkV5fmk"}},{"cell_type":"code","source":["prompt = \" it is\"\n","tokenized_prompt = tokenizer(prompt, return_tensors='pt')\n","tokenized_prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rtxd5TJz5EIP","executionInfo":{"status":"ok","timestamp":1682753146745,"user_tz":-330,"elapsed":943,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"4b2e1f26-50bd-4f12-8000-380e9c978e52"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[ 101, 1122, 1110,  102]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["outputs = model(\n","    tokenized_prompt['input_ids'][:, :-1].to(device),\n","    tokenized_prompt['attention_mask'][:,:-1].to(device)\n",")\n","outputs.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dz5IkLnG50DM","executionInfo":{"status":"ok","timestamp":1682753283300,"user_tz":-330,"elapsed":804,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"d5009e1d-f9ee-45de-e657-07533b9f54ca"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 3, 28996])"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["prediction_ids = torch.argmax(outputs[:,-1,:], axis=-1)"],"metadata":{"id":"QJAf0gML6Vhn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.decode(prediction_ids[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"HqThWOCP6iQ-","executionInfo":{"status":"ok","timestamp":1682753372641,"user_tz":-330,"elapsed":2781,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"8f3b5da2-290c-43bd-e739-8fcda336f9ae"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'a'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["prompt = \" it is a hi ##lar in\"\n","tokenized_prompt = tokenizer(prompt, return_tensors='pt')\n","tokenized_prompt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UIDGyeby6mv9","executionInfo":{"status":"ok","timestamp":1682753557519,"user_tz":-330,"elapsed":1073,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"84c70518-48f7-48a3-bb51-73d8836d47c3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[  101,  1122,  1110,   170, 20844,   108,   108,  2495,  1197,  1107,\n","           102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["outputs = model(\n","    tokenized_prompt['input_ids'][:, :-1].to(device),\n","    tokenized_prompt['attention_mask'][:,:-1].to(device)\n",")\n","outputs.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ADMqlsYn662P","executionInfo":{"status":"ok","timestamp":1682753557519,"user_tz":-330,"elapsed":5,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"d42126bb-579e-4640-8928-98cf8c1e0909"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 10, 28996])"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["prediction_ids = torch.argmax(outputs[:,-1,:], axis=-1)\n","tokenizer.decode(prediction_ids[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"aDfTmrev6-3s","executionInfo":{"status":"ok","timestamp":1682753561708,"user_tz":-330,"elapsed":3,"user":{"displayName":"Gourav Sinha","userId":"18357299038725972194"}},"outputId":"f1d53083-6f1b-43f8-9f12-947c7160a20b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'a'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":69}]}]}